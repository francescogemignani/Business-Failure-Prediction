# install.packages("sjmisc")
# devtools::install_github("ropensci/skimr")
library(skimr)
library(ggplot2)
library(hrbrthemes)
library(forcats)
library(plyr)
library(plugdensity)
# clean all
rm(list=ls())
# working dir
wdir_fg = "/Users/francescogemignani/Google Drive/SMD/_Risk-of-business-failure/git"
wdir_ff = "C:/Users/falle/OneDrive - University of Pisa/Data Science/Statistical Methods for Data Science/smdproject2021"
wdir_sc = "/Users/samuele/University/2.SMD/Risk-of-Business-Failure"
setwd(wdir_fg)
# import aida dataset
aida_fg = "../aida.RData"
aida_sc = ""
aida_ff = ""
load(file="../aida.RData")
# For each attribute name, replace all white space whit dot symbol
colnames(aida) <- gsub(" ",".",colnames(aida))
skim(aida)
# Add 'Failed' feature to AIDA dataset. It describe if a company is failed or not regardless of the cause. In particular a company with Legal status no active has marked with Failed = Yes,,
# otherwise Failed = No when has labeled as Active.
# Missing values don't occour
aida[is.na(aida$Legal.status),]
# Table of Legal status
table(aida$Legal.status)*100/nrow(aida)
# Make the operator
'%!in%' <- function(x,y)!('%in%'(x,y))
# Add new empty column
aida$Failed <- NULL
# For each 'Legal status' which contains 'Active' substring fill in new column 'No' else 'Yes'
act_vector <- c('Active','Active (default of payments)','Active (receivership)')
aida[aida$Legal.status %in% act_vector,'Failed'] <- 'No'
aida[aida$Legal.status %!in% act_vector,'Failed'] <- 'Yes'
aida[is.na(aida$Failed), ]
# Failed info
table(aida$Failed)*100/nrow(aida)
table(aida$Failed)*100/nrow(aida)
ggplot(data=aida, aes(x=Failed, fill=Legal.status)) +
geom_bar() +
scale_fill_hue(c = 90)
table(aida$Failed)*100/nrow(aida)
ggplot(data=aida, aes(x=Failed, fill=Legal.form)) +
geom_bar() +
scale_fill_hue(c = 90)
# Add a column with the respective ISTAT sector of the company. In particular first two digits of ATECO 2007code identify the company sector which is an upper case character that began to [A-U] alphabetical range.
#Delete record with ADECO code null (18327)
aida <- aida[!is.na(aida$ATECO.2007code),]
# Add the attribute 'ATECO.Sector.Code' which contain the characters of the sector identified by the first two ATECO 2007 code digits.
aida$ATECO.Sector.Code <- NULL
aida$ATECO.Sector.Code <- substr(aida$ATECO.2007code, 0, 2)
# Make a dataframe called istat.sectors.map, which contains two features:
# 1. ATECO.Sector.Code: first two digits of 'ATECO 2007code'
# 2. ATECO.Sector.Name: the respective sector name of that ATECO.Sector.Code
# Istat sectors can be found in https://www.istat.it/it/archivio/17888
ATECO.Sector.Code <- c('01', '02', '03', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '35', '36', '37', '38', '39', '41', '42', '43', '45', '46', '47', '49', '50', '51', '52', '53', '55', '56', '58', '59', '60', '61', '62', '63', '64', '65', '66', '68', '69', '70', '71', '72', '73', '74', '75', '77', '78', '79', '80', '81', '82', '84', '85', '86', '87', '88', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '00')
ATECO.Sector.Name <- c('A', 'A', 'A', 'B', 'B', 'B', 'B', 'B', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'D', 'E', 'E', 'E', 'E', 'F', 'F', 'F', 'G', 'G', 'G', 'H', 'H', 'H', 'H', 'H', 'I', 'I', 'J', 'J', 'J', 'J', 'J', 'J', 'K', 'K', 'K', 'L', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'P', 'Q', 'Q', 'Q', 'R', 'R', 'R', 'R', 'S', 'S', 'S', 'T', 'T','U', 'no.sector')
istat.sectors.map <- data.frame(ATECO.Sector.Code=ATECO.Sector.Code, ATECO.Sector.Name=ATECO.Sector.Name)
# Merge istat.sectors.map with AIDA dataframe, by ATECO.Sector.Code key
aida <- merge(aida,istat.sectors.map,by="ATECO.Sector.Code")
# Delete ATECO.Sector.Code feature, because we already have the secor name.
aida$ATECO.Sector.Code <- NULL
# Cast ATECO.Sector.Name as Factor
aida$ATECO.Sector.Name <- as.factor(aida$ATECO.Sector.Name)
# Description of ISTAT sectors
# https://www.istat.it/it/archivio/17888
# http://www.fr.camcom.gov.it/sites/default/files/cciaa/RinnovoConsiglio/ateco-2007-struttura.pdf
#Remove Missing Values
aida <- aida[!is.na(aida$Legal.form),]
table(aida$Legal.status)*100/nrow(aida)
ggplot(data=aida, aes(x=fct_rev(fct_infreq(Legal.status)), fill=Legal.status)) +
geom_bar() +
scale_fill_hue(c = 40) +
theme(legend.position="none") +
coord_flip()
table(aida$Legal.form)*100/nrow(aida)
ggplot(data=aida, aes(x=fct_rev(fct_infreq(Legal.form)), fill=Legal.form)) +
geom_bar() +
scale_fill_hue(c = 40) +
theme(legend.position="none") +
coord_flip()
# The company age is defined as as the difference between Incorporation.year and Last.accounting.closing.date
age.df <- aida
# Handle Incorporation.year: missing values occour
summary(age.df$Incorporation.year)
# Handle Last.accounting.closing.date:  no missing values
summary(age.df$Last.accounting.closing.date)
# Print the median for each sector of Incorporation.year
tapply(age.df$Incorporation.year,age.df$ATECO.Sector.Name,median, na.rm=TRUE)
# For each ATECO.Sector.Name group replace the 'Incorporation year' nan value with the respective median. In this way the result is more accurate than computing the median on entire Incorporation.year values.
compute.median <- function(x) replace(x, is.na(x), median(x, na.rm = TRUE))
age.df <- ddply(age.df,~ATECO.Sector.Name,transform, Incorporation.year = compute.median(`Incorporation.year`))
# Compute 'Age' attribute
age.df$Age <- age.df$Last.accounting.closing.date - age.df$Incorporation.year
age.df$Age <- as.integer(age.df$Age)
# Anomalies
# There are some company with negative age, with Incorporation year greater then Last accounting closing date. We suppose that are digit error. Therefore we remove all that records
summary(age.df$Age)
head(age.df[age.df$Age > 35.5,c('Age','Last.accounting.closing.date','Incorporation.year')])
# Remove negative ages
age.df <- age.df[age.df$Age >= 0,]
# Age Anomaly Detection: iqr range approach
iqr <- IQR(age.df$Age)
q1 <- quantile(age.df$Age,0.25)
q3 <- quantile(age.df$Age,0.75)
lower.whisker <- q1 - 1.5*iqr
upper.whisker <- q3 + 1.5*iqr
outliers <- age.df[age.df$Age < lower.whisker | age.df$Age > upper.whisker,'Age']
table(outliers)
boxplot(age.df$Age)
# We decided to don't remove outliers because are not error/noise but companies with higher age. The boxplot shows that the age between the median and the maximum age is sparse.
ggplot(data = age.df) +
geom_histogram(mapping=aes(x=Age, fill=Failed),binwidth = 2,color="#e9ecef", alpha=0.6, position = 'identity') +
scale_fill_manual(values=c("#69b3a2", "#404080"))+
theme_ipsum() +
labs(fill='Failed')
# Il legislatore attribuisce la dimensione di un'azienda in base al totale degli elementi che costituiscono l'attivo dello stato patrimoniale, al risultato di esercizio ed al numero di dipendenti. Nel nostro caso abbiamo deciso di attribuire a size il totale delle attivit√† dello sp, in particolare abbiamo considerato il totale degli assets nell'ultimo anno disponibile per esprimere il valore  degli impieghi di un'azienda.
size.df <- aida
# We consider all the company without nan value in total assets last available.
size.df <- size.df[!is.na(size.df$Total.assetsth.EURLast.avail..yr),]
summary(size.df$Total.assetsth.EURLast.avail..yr)
# Anomaly detection
# Before outliers detection
boxplot(size.df$Total.assetsth.EURLast.avail..yr)
plot(density(size.df$Total.assetsth.EURLast.avail..yr))
# Size Anomaly Detection: iqr range approach
iqr <- IQR(size.df$Total.assetsth.EURLast.avail..yr)
q1 <- quantile(size.df$Total.assetsth.EURLast.avail..yr,0.25)
q3 <- quantile(size.df$Total.assetsth.EURLast.avail..yr,0.75)
lower.whisker <- q1 - 1.5*iqr
upper.whisker <- q3 + 1.5*iqr
# Remove all outliers not between [q1-1.5*iqr,q3+1.5*iqr] (external from two whiskers)
size.df <- size.df[size.df$Total.assetsth.EURLast.avail..yr >= lower.whisker & size.df$Total.assetsth.EURLast.avail..yr <= upper.whisker,]
#After outliers detection
boxplot(size.df$Total.assetsth.EURLast.avail..yr)
plot(density(size.df$Total.assetsth.EURLast.avail..yr))
# ggplot2 size plots
ggplot( data=size.df, aes(x=Total.assetsth.EURLast.avail..yr) ) +
geom_density(fill="#69b3a2", color="#e9ecef", alpha=0.8)
ggplot(data=size.df, aes(x=Total.assetsth.EURLast.avail..yr, group=Failed, fill=Failed)) +
geom_density(adjust=1.5, alpha=.4) +
theme_ipsum()
# Reduce the aida dataset from all that companies which report ROI of all last three years. Obviously all missing values are been deleted. The dataset is composed by 386.629 companies (20.61%)
roi.df <- aida
colnames(roi.df)[65:67] <- c('ROI.last.avail','ROI.one.year.ago','ROI.two.years.ago')
b<- nrow(roi.df)
roi.df <- roi.df[!is.na(roi.df$ROI.last.avail),]
roi.df <- roi.df[!is.na(roi.df$ROI.one.year.ago),]
roi.df <- roi.df[!is.na(roi.df$ROI.two.years.ago),]
a <- nrow(roi.df)
ratio <- a*100/b
# Add attribute avg.roi which rappresents the average ROI of the last three years.
roi.df$avg.roi <- (roi.df$ROI.last.avail + roi.df$ROI.one.year.ago + roi.df$ROI.two.years.ago)/3
summary(roi.df$avg.roi)
# ROI Anomaly Detection: iqr range approach
iqr <- IQR(roi.df$avg.roi)
q1 <- quantile(roi.df$avg.roi,0.25)
q3 <- quantile(roi.df$avg.roi,0.75)
lower.whisker <- q1 - 1.5*iqr
upper.whisker <- q3 + 1.5*iqr
outliers <- roi.df[roi.df$avg.roi < lower.whisker | roi.df$avg.roi > upper.whisker,c('avg.roi')]
#table(outliers)
boxplot(roi.df$avg.roi)
# The outliers are companies with the higher and lower roi. We don't remove these record because the roi dataset composed only from 20.61% of record and could be usefull.
ggplot(data = roi.df) +
geom_histogram(mapping=aes(x=avg.roi, fill=Failed),binwidth = 1,color="#e9ecef", alpha=0.6, position = 'identity') +
scale_fill_manual(values=c("#69b3a2", "#404080"))+
theme_ipsum() +
labs(fill='Failed')
summary(aida$`Solvency.ratio.(%)%Last.avail..yr`)
# Deleting missing values
solvency.df <- aida
b<- nrow(solvency.df)
solvency.df <- solvency.df[!is.na(solvency.df$`Solvency.ratio.(%)%Last.avail..yr`),]
solvency.df <- solvency.df[!is.na(solvency.df$`Solvency.ratio.(%)%Year.-.1`),]
solvency.df <- solvency.df[!is.na(solvency.df$`Solvency.ratio.(%)%Year.-.2`),]
a <- nrow(solvency.df)
ratio <- a*100/b
# Add attribute avg.size which rappresents the average size of the last three years.
solvency.df$avg.solvency <- round((solvency.df$`Solvency.ratio.(%)%Last.avail..yr`
+ solvency.df$`Solvency.ratio.(%)%Year.-.1` + solvency.df$`Solvency.ratio.(%)%Year.-.2`)/3)
summary(solvency.df$avg.solvency)
# ROI Anomaly Detection: iqr range approach
iqr <- IQR(solvency.df$avg.solvency)
q1 <- quantile(solvency.df$avg.solvency,0.25)
q3 <- quantile(solvency.df$avg.solvency,0.75)
lower.whisker <- q1 - 1.5*iqr
upper.whisker <- q3 + 1.5*iqr
outliers <- solvency.df[solvency.df$avg.solvency < lower.whisker | solvency.df$avg.solvency > upper.whisker,c('avg.solvency')]
#table(outliers)
boxplot(solvency.df$avg.solvency)
# The avg.solvency distribution is well balanced and doesn't show any anomaly
ggplot(data = solvency.df) +
geom_histogram(mapping=aes(x=avg.solvency, fill=Failed),binwidth = 2,color="#e9ecef", alpha=0.6, position = 'identity') +
scale_fill_manual(values=c("#69b3a2", "#404080"))+
theme_ipsum() +
labs(fill='Failed')
