tapply(age.df$Incorporation.year,age.df$ATECO.Sector.Name,median, na.rm=TRUE)
# For each ATECO.Sector.Name group replace the 'Incorporation year' nan value with the respective median. In this way the result is more accurate than computing the median on entire Incorporation.year values.
compute.median <- function(x) replace(x, is.na(x), median(x, na.rm = TRUE))
age.df <- ddply(age.df,~ATECO.Sector.Name,transform, Incorporation.year = compute.median(`Incorporation.year`))
# Compute 'Age' attribute
age.df$Age <- age.df$Last.accounting.closing.date - age.df$Incorporation.year
age.df$Age <- as.integer(age.df$Age)
# Anomalies
# There are some company with negative age, with Incorporation year greater then Last accounting closing date. We suppose that are digit error. Therefore we remove all that records
summary(age.df$Age)
head(age.df[age.df$Age > 35.5,c('Age','Last.accounting.closing.date','Incorporation.year')])
# Remove negative ages
age.df <- age.df[age.df$Age >= 0,]
# Age Anomaly Detection: iqr range approach
iqr <- IQR(age.df$Age)
q1 <- quantile(age.df$Age,0.25)
q3 <- quantile(age.df$Age,0.75)
lower.whisker <- q1 - 1.5*iqr
upper.whisker <- q3 + 1.5*iqr
outliers <- age.df[age.df$Age < lower.whisker | age.df$Age > upper.whisker,'Age']
table(outliers)
boxplot(age.df$Age)
# We decided to don't remove outliers because are not error/noise but companies with higher age. The boxplot shows that the age between the median and the maximum age is sparse.
# export age.df
age.df <- age.df[,c('Age','Legal.form','ATECO.Sector.Name','Registered.office.address...Region','Last.accounting.closing.date','Failed')]
skim(age.df)
save(age.df, file="./dataset/age_df.RData") # R binary format
# Il legislatore attribuisce la dimensione di un'azienda in base al totale degli elementi che costituiscono l'attivo dello stato patrimoniale, al risultato di esercizio ed al numero di dipendenti. Nel nostro caso abbiamo deciso di attribuire a size il totale delle attivitÃ  dello sp, in particolare abbiamo considerato il totale degli assets nell'ultimo anno disponibile per esprimere il valore  degli impieghi di un'azienda.
size.df <- aida
# We consider all the company without nan value in total assets last available.
size.df <- size.df[!is.na(size.df$Total.assetsth.EURLast.avail..yr),]
summary(size.df$Total.assetsth.EURLast.avail..yr)
# Anomaly detection
# Before outliers detection
boxplot(size.df$Total.assetsth.EURLast.avail..yr)
plot(density(size.df$Total.assetsth.EURLast.avail..yr))
# Size Anomaly Detection: iqr range approach
iqr <- IQR(size.df$Total.assetsth.EURLast.avail..yr)
q1 <- quantile(size.df$Total.assetsth.EURLast.avail..yr,0.25)
q3 <- quantile(size.df$Total.assetsth.EURLast.avail..yr,0.75)
lower.whisker <- q1 - 1.5*iqr
upper.whisker <- q3 + 1.5*iqr
# Remove all outliers not between [q1-1.5*iqr,q3+1.5*iqr] (external from two whiskers)
size.df <- size.df[size.df$Total.assetsth.EURLast.avail..yr >= lower.whisker & size.df$Total.assetsth.EURLast.avail..yr <= upper.whisker,]
#After outliers detection
boxplot(size.df$Total.assetsth.EURLast.avail..yr)
plot(density(size.df$Total.assetsth.EURLast.avail..yr))
# export age.df
size.df <- size.df[,c('Total.assetsth.EURLast.avail..yr','Legal.form','ATECO.Sector.Name','Registered.office.address.-.Region','Last.accounting.closing.date','Failed')]
skim(size.df)
save(size.df, file="./dataset/size_df.RData") # R binary format
names(roi.df)[65:67]
roi.df <- aida
names(roi.df)[65:67]
b<- nrow(roi.df)
b
roi.df <- roi.df[!is.na(roi.df$Return.on.investment.(ROI).(%)%Last.avail..yr),]
roi.df <- roi.df[!is.na(roi.df$'Return.on.investment.(ROI).(%)%Last.avail..yr'),]
a <- nrow(roi.df)
ratio <- a*100/b
ratio
a
b
a
ratio
roi.df <- aida
b<- nrow(roi.df)
roi.df <- roi.df[!is.na(roi.df$'Return.on.investment.(ROI).(%)%Last.avail..yr'),]
a <- nrow(roi.df)
ratio <- a*100/b
ratio
# Add attribute avg.roi which rappresents the average ROI of the last three years.
roi.df$avg.roi <- (roi.df$ROI.last.avail + roi.df$ROI.one.year.ago + roi.df$ROI.two.years.ago)/3
# Take all that companies which report ROI of last available year. Obviously all missing values are been deleted. The dataset is composed by 735.268 companies (39.20%)
roi.df <- aida
b<- nrow(roi.df)
roi.df <- roi.df[!is.na(roi.df$'Return.on.investment.(ROI).(%)%Last.avail..yr'),]
a <- nrow(roi.df)
ratio <- a*100/b
summary(roi.df$avg.roi)
# Take all that companies which report ROI of last available year. Obviously all missing values are been deleted. The dataset is composed by 735.268 companies (39.20%)
roi.df <- aida
b<- nrow(roi.df)
roi.df <- roi.df[!is.na(roi.df$'Return.on.investment.(ROI).(%)%Last.avail..yr'),]
a <- nrow(roi.df)
ratio <- a*100/b
summary(roi.df$'Return.on.investment.(ROI).(%)%Last.avail..yr')
# ROI Anomaly Detection: iqr range approach
iqr <- IQR(roi.df$'Return.on.investment.(ROI).(%)%Last.avail..yr')
q1 <- quantile(roi.df$avg.roi,0.25)
q3 <- quantile(roi.df$avg.roi,0.75)
lower.whisker <- q1 - 1.5*iqr
upper.whisker <- q3 + 1.5*iqr
outliers <- roi.df[roi.df$'Return.on.investment.(ROI).(%)%Last.avail..yr' < lower.whisker |
roi.df$'Return.on.investment.(ROI).(%)%Last.avail..yr' > upper.whisker,c('Return.on.investment.(ROI).(%)%Last.avail..yr')]
#table(outliers)
boxplot(roi.df$avg.roi)
# Take all that companies which report ROI of last available year. Obviously all missing values are been deleted. The dataset is composed by 735.268 companies (39.20%)
roi.df <- aida
b<- nrow(roi.df)
roi.df <- roi.df[!is.na(roi.df$'Return.on.investment.(ROI).(%)%Last.avail..yr'),]
a <- nrow(roi.df)
ratio <- a*100/b
summary(roi.df$'Return.on.investment.(ROI).(%)%Last.avail..yr')
iqr <- IQR(roi.df$'Return.on.investment.(ROI).(%)%Last.avail..yr')
q1 <- quantile(roi.df$'Return.on.investment.(ROI).(%)%Last.avail..yr',0.25)
q3 <- quantile(roi.df$'Return.on.investment.(ROI).(%)%Last.avail..yr',0.75)
lower.whisker <- q1 - 1.5*iqr
upper.whisker <- q3 + 1.5*iqr
outliers <- roi.df[roi.df$'Return.on.investment.(ROI).(%)%Last.avail..yr' < lower.whisker |
roi.df$'Return.on.investment.(ROI).(%)%Last.avail..yr' > upper.whisker,c('Return.on.investment.(ROI).(%)%Last.avail..yr')]
boxplot(roi.df$'Return.on.investment.(ROI).(%)%Last.avail..yr')
table(outliers)
table(outliers>0)
outliers
table(outliers)
roi.df <- roi.df[,c('Return.on.investment.(ROI).(%)%Last.avail..yr','Legal.form','ATECO.Sector.Name','Registered.office.address.-.Region','Last.accounting.closing.date','Failed')]
skim(roi.df)
save(roi.df, file="./dataset/roi_df.RData") # R binary format
library(skimr)
library(ggplot2)
library(hrbrthemes)
library(forcats)
# clean all
rm(list=ls())
# working dir
wdir_fg = "/Users/francescogemignani/Google Drive/SMD/_Risk-of-business-failure/git"
wdir_ff = "C:/Users/falle/OneDrive - University of Pisa/Data Science/Statistical Methods for Data Science/smdproject2021"
wdir_sc = "/Users/samuele/University/2.SMD/Risk-of-Business-Failure"
setwd(wdir_fg)
# import aida dataset
load("./dataset/age_df.RData") # reload energy dataset
#summary
skim(age.df)
#dataset
head(age.df)
ggplot(data = age.df) +
geom_histogram(mapping=aes(x=Age, fill=Failed),binwidth = 2,color="#e9ecef", alpha=0.6, position = 'identity') +
scale_fill_manual(values=c("#69b3a2", "#404080"))+
theme_ipsum() +
labs(fill='Failed')
# import aida dataset
load("./dataset/size_df.RData") # reload energy dataset
#summary
skim(size.df)
#dataset
head(size.df)
# ggplot2 size plots
ggplot( data=size.df, aes(x=Total.assetsth.EURLast.avail..yr) ) +
geom_density(fill="#69b3a2", color="#e9ecef", alpha=0.8)
ggplot(data=size.df, aes(x=Total.assetsth.EURLast.avail..yr, group=Failed, fill=Failed)) +
geom_density(adjust=1.5, alpha=.4) +
theme_ipsum()
# import aida dataset
load("./dataset/roi_df.RData") # reload energy dataset
#summary
skim(roi.df)
#dataset
head(roi.df)
ggplot(data = roi.df) +
geom_histogram(mapping=aes(x=avg.roi, fill=Failed),binwidth = 1,color="#e9ecef", alpha=0.6, position = 'identity') +
scale_fill_manual(values=c("#69b3a2", "#404080"))+
theme_ipsum() +
labs(fill='Failed')
ggplot(data = roi.df) +
geom_histogram(mapping=aes(x='Return.on.investment.(ROI).(%)%Last.avail..yr', fill=Failed),binwidth = 1,color="#e9ecef", alpha=0.6, position = 'identity') +
scale_fill_manual(values=c("#69b3a2", "#404080"))+
theme_ipsum() +
labs(fill='Failed')
ggplot(data = roi.df) +
geom_histogram(mapping=aes(x=Return.on.investment.(ROI).(%)%Last.avail..yr, fill=Failed),binwidth = 1,color="#e9ecef", alpha=0.6, position = 'identity') +
a <- 'Return.on.investment.(ROI).(%)%Last.avail..yr'
ggplot(data = roi.df) +
geom_histogram(mapping=aes(x=a, fill=Failed),binwidth = 1,color="#e9ecef", alpha=0.6, position = 'identity') +
scale_fill_manual(values=c("#69b3a2", "#404080"))+
theme_ipsum() +
labs(fill='Failed')
ggplot(data = roi.df) +
geom_histogram(mapping=aes(x=`Return.on.investment.(ROI).(%)%Last.avail..yr`, fill=Failed),binwidth = 1,color="#e9ecef", alpha=0.6, position = 'identity') +
scale_fill_manual(values=c("#69b3a2", "#404080"))+
theme_ipsum() +
labs(fill='Failed')
library(skimr)
library(ggplot2)
library(hrbrthemes)
library(forcats)
# clean all
rm(list=ls())
# working dir
wdir_fg = "/Users/francescogemignani/Google Drive/SMD/_Risk-of-business-failure/git"
wdir_ff = "C:/Users/falle/OneDrive - University of Pisa/Data Science/Statistical Methods for Data Science/smdproject2021"
wdir_sc = "/Users/samuele/University/2.SMD/Risk-of-Business-Failure"
setwd(wdir_fg)
# import aida dataset
load("./dataset/age_df.RData") # reload energy dataset
#summary
skim(age.df)
#dataset
head(age.df)
ggplot(data=age.df, aes(x=Age, group=Failed, fill=Failed)) +
geom_density(adjust=1.5, alpha=.4) +
theme_ipsum()
ggplot(data = age.df) +
geom_histogram(mapping=aes(x=Age, fill=Failed),binwidth = 2,color="#e9ecef", alpha=0.6, position = 'identity') +
scale_fill_manual(values=c("#69b3a2", "#404080"))+
theme_ipsum() +
labs(fill='Failed')
ggplot(data=age.df, aes(x=Age, group=Failed, fill=Failed)) +
geom_density(adjust=1.5, alpha=.4) +
theme_ipsum()
age.df
library(skimr)
library(ggplot2)
library(hrbrthemes)
library(forcats)
# clean all
rm(list=ls())
# working dir
wdir_fg = "/Users/francescogemignani/Google Drive/SMD/_Risk-of-business-failure/git"
wdir_ff = "C:/Users/falle/OneDrive - University of Pisa/Data Science/Statistical Methods for Data Science/smdproject2021"
wdir_sc = "/Users/samuele/University/2.SMD/Risk-of-Business-Failure"
setwd(wdir_fg)
# import aida dataset
load("./dataset/age_df.RData") # reload energy dataset
#summary
skim(age.df)
#dataset
head(age.df)
table(age.df$Age)
table(age.df$Last.accounting.closing.date)
library(skimr)
library(ggplot2)
library(hrbrthemes)
library(forcats)
# clean all
rm(list=ls())
# working dir
wdir_fg = "/Users/francescogemignani/Google Drive/SMD/_Risk-of-business-failure/git"
wdir_ff = "C:/Users/falle/OneDrive - University of Pisa/Data Science/Statistical Methods for Data Science/smdproject2021"
wdir_sc = "/Users/samuele/University/2.SMD/Risk-of-Business-Failure"
setwd(wdir_fg)
# import aida dataset
load("./dataset/age_df.RData") # reload energy dataset
#summary
skim(age.df)
#dataset
head(age.df)
typeof(age.df$Last.accounting.closing.date)
age.df.2018 <- age[age.df$Last.accounting.closing.date == 2018]
age.df.2018 <- age[age.df$Last.accounting.closing.date == 2018,]
age.df.2018 <- age.df[age.df$Last.accounting.closing.date == 2018,]
nrow(age.df)
table(age.df$Last.accounting.closing.date)
# We selected  2018 as year because has the highest frequency
table(age.df$Last.accounting.closing.date)
age.df.2018 <- age.df[age.df$Last.accounting.closing.date == 2018,]
skim(age.df.2018)
ggplot(data = age.df.2018) +
geom_histogram(mapping=aes(x=Age, fill=Failed),binwidth = 2,color="#e9ecef", alpha=0.6, position = 'identity') +
scale_fill_manual(values=c("#69b3a2", "#404080"))+
theme_ipsum() +
labs(fill='Failed')
ggplot(data=age.df.2018, aes(x=Age, group=Failed, fill=Failed)) +
geom_density(adjust=1.5, alpha=.4) +
theme_ipsum()
ggplot(data = age.df.2018) +
geom_histogram(mapping=aes(x=Age, fill=Failed),binwidth = 2,color="#e9ecef", alpha=0.6, position = 'identity') +
scale_fill_manual(values=c("#69b3a2", "#404080"))+
theme_ipsum() +
labs(fill='Failed')
ggplot(data=age.df.2018, aes(x=Age, group=Failed, fill=Failed)) +
geom_density(adjust=1.5, alpha=.4) +
theme_ipsum()
skim(age.df.2018)
# We selected 2018 as year because has the highest frequency
table(age.df$Last.accounting.closing.date)
age.df.2018 <- age.df[age.df$Last.accounting.closing.date == 2018,]
skim(age.df.2018)
ggplot(data = age.df.2018) +
geom_histogram(mapping=aes(x=Age, fill=Failed),binwidth = 2,color="#e9ecef", alpha=0.6, position = 'identity') +
scale_fill_manual(values=c("#69b3a2", "#404080"))+
theme_ipsum() +
labs(fill='Failed')
ggplot(data=age.df.2018, aes(x=Age, group=Failed, fill=Failed)) +
geom_density(adjust=1.5, alpha=.4) +
theme_ipsum()
company.forms <- unique(age.df.2018$Legal.form)
company.forms
table(company.forms)
table(age.df.2018$Legal.form)
company.forms
table(age.df.2018$Legal.form)*100/nrow(age.df.2018)
table(age.df.2018$Legal.form)
company.forms <- unique(age.df.2018$Legal.form)
ggplot(data=age.df.2018, aes(x=fct_rev(fct_infreq(Legal.form)), fill=Legal.form)) +
geom_bar() +
scale_fill_hue(c = 40) +
theme(legend.position="none") +
coord_flip()
table(age.df.2018$Legal.form)
ggplot(data=age.df.2018, aes(x=fct_rev(fct_infreq(Legal.form)), fill=Legal.form)) +
geom_bar() +
scale_fill_hue(c = 40) +
theme(legend.position="none") +
coord_flip()
company.forms <- unique(age.df.2018$Legal.form)
age.df.2018.active <- age.df.2018[age.df.2018$Failed=='No',]
age.df.2018.active
age.df.2018.active$Failed
unique(age.df.2018.active)
aa<-unique(age.df.2018.active)
aa<-unique(age.df.2018.active$Failed)
aa
age.df.2018.active <- age.df.2018[age.df.2018$Failed=='No',]
age.df.2018.active <- age.df.2018[age.df.2018$Failed=='No',]
age.df.2018.failed <- age.df.2018[age.df.2018$Failed=='Yes',]
age.df.2018.failed
age.df.2018.active
age.df.2018
age.df.2018.active <- age.df.2018[age.df.2018$Failed=='No',Age]
age.df.2018.active <- age.df.2018[age.df.2018$Failed=='No','Age']
age.df.2018.active <- age.df.2018[age.df.2018$Failed=='No','Age']
age.df.2018.failed <- age.df.2018[age.df.2018$Failed=='Yes','Age']
age.df.2018.active
age.2018.active <- age.df.2018[age.df.2018$Failed=='No','Age']
age.2018.failed <- age.df.2018[age.df.2018$Failed=='Yes','Age']
age.2018.active <- age.df.2018[age.df.2018$Failed=='No','Age']
age.2018.failed <- age.df.2018[age.df.2018$Failed=='Yes','Age']
t.test(age_failed,age_active)
age.2018.active <- age.df.2018[age.df.2018$Failed=='No','Age']
age.2018.failed <- age.df.2018[age.df.2018$Failed=='Yes','Age']
t.test(age.2018.active,age.2018.failed)
t.test(age.2018.active,age.2018.failed,alternative = 'less')
t.test(age.2018.active,age.2018.failed,alternative = 'greater')
#rm(age_failed,age_active)
age.2018.active <- age.df.2018[age.df.2018$Failed=='No','Age']
age.2018.failed <- age.df.2018[age.df.2018$Failed=='Yes','Age']
t.test(age.2018.active,age.2018.failed)
t.test(age.2018.active,age.2018.failed,alternative = 'less')
t.test(age.2018.active,age.2018.failed,alternative = 'greater')
t.test(age.2018.active,age.2018.failed,alternative = 'less')
age.2018.active <- age.df.2018[age.df.2018$Failed=='No','Age']
age.2018.failed <- age.df.2018[age.df.2018$Failed=='Yes','Age']
t.test(age.2018.active,age.2018.failed)
t.test(age.2018.active,age.2018.failed,alternative = 'less')
t.test(age.2018.active,age.2018.failed,alternative = 'greater')
age.2018.active <- age.df.2018[age.df.2018$Failed=='No','Age']
age.2018.failed <- age.df.2018[age.df.2018$Failed=='Yes','Age']
t.test(age.2018.active,age.2018.failed)
t.test(age.2018.active,age.2018.failed,alternative = 'less')
t.test(age.2018.active,age.2018.failed,alternative = 'greater')
# Il p-value dell'ipotesi nulla non Ã¨ significativo perchÃ¨ Ã¨ molto basso. Di conseguenza scarto tutte le ipotesi nulle e considero solo quelle bilaterali.
# In particolare possiamo leggere che la media dell'etÃ  delle aziende attive Ã¨ superiore alla media delle etÃ  delle aziende fallite (nel 2018): p-value = 1
# Quindi nel 2018 le aziende attive sono piÃ¹ vecchie di quelle fallite
rm(age.2018.active,age.2018.failed)
t.test(age.2018.active,age.2018.failed,alternative = 'greater')
age.2018.active <- age.df.2018[age.df.2018$Failed=='No','Age']
age.2018.failed <- age.df.2018[age.df.2018$Failed=='Yes','Age']
t.test(age.2018.active,age.2018.failed)
t.test(age.2018.active,age.2018.failed,alternative = 'less')
# Voglio sapere se la media dei valori del primo parametro Ã¨ maggiore della media dei valori del secondo parametro
t.test(age.2018.active,age.2018.failed,alternative = 'greater')
age.2018.active <- age.df.2018[age.df.2018$Failed=='No','Age']
age.2018.failed <- age.df.2018[age.df.2018$Failed=='Yes','Age']
# Voglio sapere se la media dei valori del primo parametro Ã¨ uguale alla media dei valori del secondo parametro
t.test(age.2018.active,age.2018.failed)
# Voglio sapere se la media dei valori del primo parametro Ã¨ minore della media dei valori del secondo parametro
t.test(age.2018.active,age.2018.failed,alternative = 'less')
# Voglio sapere se la media dei valori del primo parametro Ã¨ maggiore della media dei valori del secondo parametro
t.test(age.2018.active,age.2018.failed,alternative = 'greater')
# RISULTATO
# Il p-value dell'ipotesi nulla non Ã¨ significativo perchÃ¨ Ã¨ molto basso. Di conseguenza scarto l'ipotesi nulle e considero solo quelle bilaterali, in particolare
# l'ipotesi bilateriale superiore. In tal caso il p-value Ã¨ pari a 1, e questo ci porta ad accettare l'ipotesi bilaterale superiore, ovvero che la media dell'etÃ 
# dell'etÃ  delle aziende attive Ã¨ superiore alla media delle etÃ  delle aziende fallite (nel 2018).
# Quindi nel 2018 le aziende attive sono piÃ¹ vecchie di quelle fallite
rm(age.2018.active,age.2018.failed)
# Simple bar chart of legal form
ggplot(data=age.df.2018, aes(x=fct_rev(fct_infreq(Legal.form)), fill=Legal.form)) +
geom_bar() +
scale_fill_hue(c = 40) +
theme(legend.position="none") +
coord_flip()
# List of unique legal form values
company.forms <- unique(age.df.2018$Legal.form)
# Simple bar chart of legal form
ggplot(data=age.df.2018, aes(x=fct_rev(fct_infreq(Legal.form)), fill=Legal.form)) +
geom_bar() +
scale_fill_hue(c = 40) +
theme(legend.position="none") +
coord_flip()
# List of unique legal form values
company.forms <- unique(age.df.2018$Legal.form)
ggplot(data = age.df.2018) +
geom_histogram(mapping=aes(x=Age, fill=Failed),binwidth = 2,color="#e9ecef", alpha=0.6, position = 'identity') +
scale_fill_manual(values=c("#69b3a2", "#404080"))+
theme_ipsum() +
labs(fill='Failed')
ggplot(data=age.df.2018, aes(x=Age, group=Failed, fill=Failed)) +
geom_density(adjust=1.5, alpha=.4) +
theme_ipsum()
# simple bar chart of legal form of companies at year 2018
ggplot(data=age.df.2018, aes(x=fct_rev(fct_infreq(Legal.form)), fill=Legal.form)) +
geom_bar() +
scale_fill_hue(c = 40) +
theme(legend.position="none") +
coord_flip()
age.2018.active <- age.df.2018[age.df.2018$Failed=='No','Age']
age.2018.failed <- age.df.2018[age.df.2018$Failed=='Yes','Age']
# Voglio sapere se la media dei valori del primo parametro Ã¨ uguale alla media dei valori del secondo parametro
t.test(age.2018.active,age.2018.failed)
# Voglio sapere se la media dei valori del primo parametro Ã¨ minore della media dei valori del secondo parametro
t.test(age.2018.active,age.2018.failed,alternative = 'less')
# Voglio sapere se la media dei valori del primo parametro Ã¨ maggiore della media dei valori del secondo parametro
t.test(age.2018.active,age.2018.failed,alternative = 'greater')
# Remove data from stack
rm(age.2018.active,age.2018.failed)
# RISULTATO
# Il p-value dell'ipotesi nulla non Ã¨ significativo perchÃ¨ Ã¨ molto basso. Di conseguenza scarto l'ipotesi nulle e considero solo quelle bilaterali, in particolare
# l'ipotesi bilateriale superiore. In tal caso il p-value Ã¨ pari a 1, e questo ci porta ad accettare l'ipotesi bilaterale superiore, ovvero che la media dell'etÃ 
# dell'etÃ  delle aziende attive Ã¨ superiore alla media delle etÃ  delle aziende fallite (nel 2018).
# Quindi nel 2018 le aziende attive sono piÃ¹ vecchie di quelle fallite
# List of unique legal form values
company.forms <- unique(age.df.2018$Legal.form)
company.forms
# List of unique legal form values
company.forms <- unique(age.df.2018$Legal.form)
age.2018.active <- age.df.2018[age.df.2018$Failed=='No' & age.df.2018$Legal.form=='S.P.A.' ,'Age']
age.2018.failed <- age.df.2018[age.df.2018$Failed=='Yes'& age.df.2018$Legal.form=='S.P.A.' ,'Age']
# Voglio sapere se la media dei valori del primo parametro Ã¨ uguale alla media dei valori del secondo parametro
t.test(age.2018.active,age.2018.failed)
# Voglio sapere se la media dei valori del primo parametro Ã¨ minore della media dei valori del secondo parametro
t.test(age.2018.active,age.2018.failed,alternative = 'less')
# Voglio sapere se la media dei valori del primo parametro Ã¨ maggiore della media dei valori del secondo parametro
t.test(age.2018.active,age.2018.failed,alternative = 'greater')
# Remove data from stack
rm(age.2018.active,age.2018.failed)
age.2018.active <- age.df.2018[age.df.2018$Failed=='No' & age.df.2018$Legal.form=='S.P.A.' ,'Age']
age.2018.failed <- age.df.2018[age.df.2018$Failed=='Yes'& age.df.2018$Legal.form=='S.P.A.' ,'Age']
age.2018.active
age.2018.active <- age.df.2018[age.df.2018$Failed=='No' & age.df.2018$Legal.form=='S.P.A.' ,]
age.2018.active
age.2018.active <- age.df.2018[age.df.2018$Failed=='No' & age.df.2018$Legal.form=='S.P.A.' ,]
age.2018.active
age.2018.active <- age.df.2018[age.df.2018$Failed=='No' & age.df.2018$Legal.form=='S.P.A.' ,'Age']
age.2018.failed <- age.df.2018[age.df.2018$Failed=='Yes'& age.df.2018$Legal.form=='S.P.A.' ,'Age']
t.test(age.2018.active,age.2018.failed)
t.test(age.2018.active,age.2018.failed,alternative = 'less')
t.test(age.2018.active,age.2018.failed,alternative = 'greater')
ggplot(data = age.df.2018) +
geom_histogram(mapping=aes(x=Age, fill=Failed),binwidth = 2,color="#e9ecef", alpha=0.6, position = 'identity') +
scale_fill_manual(values=c("#69b3a2", "#404080"))+
theme_ipsum() +
labs(fill='Failed') +
ggtitle("CIAO")
ggplot(data = age.df.2018) +
geom_histogram(mapping=aes(x=Age, fill=Failed),binwidth = 2,color="#e9ecef", alpha=0.6, position = 'identity') +
scale_fill_manual(values=c("#69b3a2", "#404080"))+
theme_ipsum() +
labs(fill='Failed') +
ggtitle("Histogram of Company ages in 2018")
ggplot(data=age.df.2018, aes(x=Age, group=Failed, fill=Failed)) +
geom_density(adjust=1.5, alpha=.4) +
theme_ipsum() +
ggtitle("Density of Company ages in 2018")
ggplot(data = age.df.2018) +
geom_histogram(mapping=aes(x=Age, fill=Failed),binwidth = 2,color="#e9ecef", alpha=0.6, position = 'identity') +
scale_fill_manual(values=c("#69b3a2", "#404080"))+
theme_ipsum() +
labs(fill='Failed') +
ggtitle("Histogram of Company ages in 2018")
ggplot(data=age.df.2018, aes(x=Age, group=Failed, fill=Failed)) +
geom_density(adjust=1.5, alpha=.4) +
theme_ipsum() +
ggtitle("Density of Company ages in 2018")
# simple bar chart of legal form of companies at year 2018
ggplot(data=age.df.2018, aes(x=fct_rev(fct_infreq(Legal.form)), fill=Legal.form)) +
geom_bar() +
scale_fill_hue(c = 40) +
theme(legend.position="none") +
coord_flip() +
ggtitle("Bar Plot of Legal Form in 2018")
ggplot(data = age.df.2018) +
geom_histogram(mapping=aes(x=Age, fill=Failed),binwidth = 2,color="#e9ecef", alpha=0.6, position = 'identity') +
scale_fill_manual(values=c("#69b3a2", "#404080"))+
theme_ipsum() +
labs(fill='Failed') +
ggtitle("Histogram of Company ages in 2018")
ggplot(data=age.df.2018, aes(x=Age, group=Failed, fill=Failed)) +
geom_density(adjust=1.5, alpha=.4) +
theme_ipsum() +
ggtitle("Density of Company ages in 2018")
# simple bar chart of legal form of companies at year 2018
ggplot(data=age.df.2018, aes(x=fct_rev(fct_infreq(Legal.form)), fill=Legal.form)) +
geom_bar() +
scale_fill_hue(c = 40) +
theme(legend.position="none") +
coord_flip() +
ggtitle("Bar Plot of Company forms in 2018")
# List of unique legal form values
company.forms <- unique(age.df.2018$Legal.form)
for(form.name in company.forms){
age.2018.active <- age.df.2018[age.df.2018$Failed=='No' & age.df.2018$Legal.form==form.name ,'Age']
age.2018.failed <- age.df.2018[age.df.2018$Failed=='Yes'& age.df.2018$Legal.form==form.name ,'Age']
# Voglio sapere se la media dei valori del primo parametro Ã¨ uguale alla media dei valori del secondo parametro
t.test(age.2018.active,age.2018.failed)
# Voglio sapere se la media dei valori del primo parametro Ã¨ minore della media dei valori del secondo parametro
t.test(age.2018.active,age.2018.failed,alternative = 'less')
# Voglio sapere se la media dei valori del primo parametro Ã¨ maggiore della media dei valori del secondo parametro
t.test(age.2018.active,age.2018.failed,alternative = 'greater')
# Remove data from stack
rm(age.2018.active,age.2018.failed)
}
